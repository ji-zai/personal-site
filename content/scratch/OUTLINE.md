Today was quite a breakthrough. The first section is quite clear, there are just a few areas of unknowns that I need to explore.

I think the shorter the beat, the better.

Outline:

**What is seeking truth?**
- Seeking truth.
- Why seek truth?
- A truth has value. - value(t) -> int
- Truths are clustered. - similarity(t1, t2) -> int
- We have an internal model of what we believe is true.
	- This is where you define delusion as how far it is from reality.
- We improve our model by wanting, observing, understanding, predicting.
- Seeking truth is a search problem.
- Patience and satiation influence how you jump between wants.
- It's a messy process (Everything changes, every moment).

**Seeking truth is a skill**
- Delusion compounds.
- As a result, seeking truth follows the power law in outcomes, because each of us has varying levels of delusion, and even small differences in delusion lead to massive differences in outcomes. It's easy to see this in the world we live in (many examples)
- What differentiates the best from the worst?
	- Use 3 examples (Steve Jobs, Marie Curie, Kurosawa, ? - choose the most universal examples across multiple fields).
- Need to talk about effort, in order to say with time, the power law is more pronounced, and with less effort it takes less time for the power law to be more pronounced.
- Skill or luck?
- What are the levers of improvement?
	- There's no need to actively focus on increasing the power of your model. It will happen on its own. Just reduce delusion.
	- How intensely you want (it has to be the right amount, because otherwise you'll be too blinded).
	- Patience and satiation.

**Seeking truth is grounded in feeling**
- What is thinking & feeling? How are they different? 
	- Sensations in the body. (and there are enough studies to reference here).
		- Show how 1+1=2 is represented in sensations (i.e. the biochemical reactions that happen inside your body).
	- Feeling captures more information than thinking.
		- Easy to show this: inner monologue, audio, visual can all be represented quite well in our existing technology to store information.
		- My belief is that the representational challenge of feeling is far greater: capturing feeling accurately is quite difficult.
		- Complexity of reality much greater than complexity of information that our senses can process.
	- Feeling is a more primal mechanism.
- Wants are grounded in feeling.
- The mind's processes are exponential: spirals upwards or downwards. Just see all collective human things to see this behavior: stock market, etc.
- Intuition.
- Patience and satiation are grounded in feeling.
- Feelings are dictated by habits.
- Our model is impacted by both thinking and feeling.
- Most feeling is in subconscious.
- Sensitivity: 
	- It is possible to bring into conscious more subconscious feeling by increasing sensitivity
- We are more similar than it seems
	- Truth seeking for any person stems from the same, shared want.
- Can you change what you feel?

**Seeking truth is the only skill**
- It takes effort to seek truth, but effort itself is not truth seeking.
- Technology reduces the effort to seek truth.
- **AI eats the tree from the bottom up (should be: AI eats entire nodes in tree)** (actually this is not true, because it's possible to have "easy" nodes at the top. For example: someone who likes to play video games because it makes them happy - well, AI can "eat that" because it's quite contained, and yet it appears at the top of the tree for this person. Fascinating).
- Lower nodes in tree search are "easier" (be clear what easier means using "time").
	- They are easier because they are more contained (even though all spaces grow complexity infinitely - fascinating paradox).
	- “With a good script, a good director can produce a masterpiece. With the same script, a mediocre director can produce a passable film. But **with a bad script even a good director can't possibly make a good film**. ” ― Akira Kurosawa
	- (i.e. a script is a higher node than implementing the script in the same way the idea for what to build is a higher node than implementing that idea in code for software).
- Not only is seeking truth the only skill for an individual to thrive in this world, I also believe it's the antidote to our collective problems. Even if someone wanting absolute power over the world today exists, if they're good at seeking truth to get that power, they'd: (the chain of events that leads them to building a decentralized, democratic country and try to become its leader). Seeking truth forces you to be aligned with the incentives that govern our world, and those incentives do not point towards the destruction of our species. In fact, destruction would only arise from either delusion (i.e. we weren't good enough at seeking truth), or by things out of our control. If latter, well, we can't do anything about it, but we can be better at seeking truth. By a lot. (to the extent that you believe it's a skill that can be trained).

**How to be better at seeking truth?**
- Low integrity has a much deeper consequence than simply not collaborating effectively: The tendency to distort reality is the same tendency that leads to bias when we seek truth in the external world. They're both an attempt to distort. Manipulating research results and deceiving investors out of their money is the same exact reaction: **reality distortion.**
A high level overview here, towards the end.
- Applying thinking AND feeling to enable you to get what you want.
- (e.g. detecting bias in feeling, as well as employing thinking tools: statistics, etc. to show any bias for you to study. It's this working together that greatly improves the rate of learning).
- bias vs. being more aligned with reality and disagreeing with someone vs. intuition vs. (there are likely more feelings here at play - for sure.).
	- One way to know is in hindsight: if hunch was right it was an intuition, else it was a bias. But that doesn't really help us does it? Well, it does if you want to be right. Wanting to be right (i.e. be aligned with the truth) is critical, because it means you feel pain when you aren't, and it's only when you feel that pain when you aren't, that your feelings are updated to lean towards intuitions rather than biases.
	- Another approach is to collaborate: naturally having more (right) people to criticize your thinking, that you'll be able to identify your biases.
	- Is there something that can be done in realtime to help with this?
	- Heuristics that make us pause.
- Can actively believing something misaligned with reality help you seek truth? Absolutely, but you should choose them cautiously, and skillfully.
	- It has to be plausible. Can't have clear evidence that hits you in the face denying it.
	- Steph curry believing he's the best person on the court - that he's not doing anything and that God operates through him.
	- PG believing he's an expert on startups. (And how I falsely believe that I've studied my mind more than the average person has studied theirs).
	- And believing in rebirth with the same mental conditioning / that aging will be solved in your lifetime (these are the only two possible beliefs that will help - and equally so, actually not equally so - one causes more stress. Anything else ).
	- In fact, without this falsifiable belief, I likely wouldn't have written this essay, thinking that by now if I didn't "achieve" something in my previous identity, that I would no longer have time to do so. That pressure would push me to do work that I believed was appropriate for that previous identity.
	- In fact, this is a critical skill to regulate the patience, satiation, and intuition to switch. Self-brainwashing is critical to navigate the truth seeking path.
	- The path truly is as narrow as a razor's edge.
- Don't be attached to a sub-want - if you get stuck you lose sight of the bigger picture.
- Why doing what you actually want to do is increasingly necessary to do great work.
	- This path is the one in which you naturally have the greatest patience with - in other words, something about seeking truth in that path gives you fulfillment on the path itself, not just when a truth is uncovered. And each of us seems to have a unique inclination.

**Predictions (not fully formed)** (not sure where to put, just dump here for now.)
*The following are all predictions that are a reaction of the above understanding. Naturally, the extent of delusion in understanding will lead to even more delusion in these predictions, as we've seen above.*
- Why genius and madness look similar. (this is likely a note within the content above - when talking about what separates novices from masters - yup.)
- AGI alignment is about creating a system analogous to the human's physical want conditioning such that the craving to not harm humans is sooo difficult that it can't possibly un-condition it. And to create an un-conditioning mechanism that is time consuming. (Basically make it like the average human, with a fixed root want.) (callout: if this resonates with someone working on alignment, I'd love to chat!)
- In order to have AGI, we need significant innovation in the fundamental computer architecture such that it can represent more complex information. Quantum computers are a step in that direction (and actually take Akshar's help to flesh this out a bit more).
- Pay-to-learn economic model will no longer work for education as anyone who would be paid for teaching, will be exponentially further from the best teacher, the more powerful technology becomes. Education will resemble how we invest in companies. Centralized, standardized education will become useless.
- Ideal education starts with an education on how the mind works and to teach kids basic techniques for how to keep calm, and how to get what they want. The next step is to teach them the bare minimum required to understand enough about seeking truth. Then, put them into the world with an AI copilot and ask them to do whatever they want. The AI copilot will help point out obvious mistakes not only in the truth seeking, but especially if any path is causing too much agitation of the mind. Will need to protect minds from over-addiction to anything, because that inhibits truth seeking.
- UBI is required. The less safety net you have, and the less truth seeking skill you have, the more suffering these next few years will become. But no one will be able to rely on it, and it will never be "enough" as the bar for what we "need" rises. And so, the concern here is that only truth seekers have an opportunity to be happy because they'll be the only ones that can get what they want. It's a concern because this is a difficult skill... but I have a bias towards optimism when it comes to the human potential. But, in all likelihood this bias is quite mis-aligned with reality.
- Credentials will no longer be valuable. It will start with the least regulated fields (Tech, arts), and eventually encompass all fields (including medicine, law, etc.).
- The bar for employment will be significantly higher. As the truth seeking in lower depths will be done by AI better than humans, "new grad" / "junior" roles will vanish in the traditional sense. Only those with an intuition for what is a good end-product will be given resources and space to operate.
- Inequality of outcomes will skyrocket as a result of the power law of truth seeking. Any group that tries to curb this inequality with force (over-regulation, etc.), will eventually be absorbed by groups that curb it less... or they'll look to destroy the entire world and take us all down with them (unlikely, but can never discount insanity).
- Saying two truths are equally the cause of something should draw suspicion. It often means that there is insufficient understanding, not because two components have an equal cause. Therefore, if you really want something, you ought to seek truth sufficiently well enough to see at least a bit of the power law distribution of the choices in front of you, and then double down on the one you see as most valuable. (i.e. leaning further into a path is likely to be more fruitful). I.e. (strong opinions, weakly held, that are also correct).
	- (A reference to this needs to be in the essay).
	- The deeper meaning here is that almost everything follows the power law as a consequence of the power law of the values of truths.
	- A good example: beginner programmers wonder which language to choose and do a variety of analyses and trade-offs. An experienced programmer knows that this choice is faaaaar less valuable than getting better at thinking, and so will tell them to pick the one that lets them create what they want right now, the most popular one that has the most tutorials, without worrying about all the analysis b/w/ languages. An even more experienced programmer will tell them that it doesn't matter what you choose as long as you can use code to create something useful. If what you make is not useful, it doesn't matter what you did. And this could go on and on and on (until you get to what you should even work on).
	- Bias towards everything following the power law, and far more forcefully than the Pareto's principle, as technology becomes more powerful. -> This is actually quite an important point.

---

I want to help build a more truth seeking world, and I believe artificial intelligence will be a critical tool to help us seek truth more effectively.

I'm about to choose one of the following topics to explore:
1. How to be better at seeking truth (a playbook for an individual to improve).
2. What we'll need to build artificial general intelligence, and why we shouldn't be overly afraid of it.
3. What tools and cultures we'll need to build a more truth seeking world.

And naturally, at the root of all of these topics is the question: "what are we?". Invariably any exploration of any worthwhile topic will force me to tackle this question.

I'm sharing these up front because after reading this essay you feel that there's something better for me to focus on, I'd love to hear it! Each essay, when done the right way, takes me months of research and thinking, so I want to choose right.